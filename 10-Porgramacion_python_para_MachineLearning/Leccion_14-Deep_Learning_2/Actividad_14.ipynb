{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "062e9ce9",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26a31253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importemos las librerías Necesarias:\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49fbeb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.layers import *\n",
    "from keras.models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a0d4f0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da39e0f",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef9ad5a",
   "metadata": {},
   "source": [
    "Dado que En intentos anteriores se ha recibido un error, haremos lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d18f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# !nvcc --version \n",
    "# !nvidia-smi\n",
    "\n",
    "# Veamos los dispositivos Fisicos de tipo GPU:\n",
    "ph_dev = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(ph_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "351bd1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\osgum\\v_env\\TnsrFlw\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:622: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.get_single_element()`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\osgum\\v_env\\TnsrFlw\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:622: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.get_single_element()`.\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tfds.as_numpy(\n",
    "    tfds.load(\n",
    "            name='rock_paper_scissors',\n",
    "            split=['train', 'test'],\n",
    "            batch_size=-1,\n",
    "            as_supervised=True\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c0a909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 300, 3), (2520,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veamos a que nos enfrentamos:\n",
    "X_train[0].shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553bb767",
   "metadata": {},
   "source": [
    "De aquí sabemos que las imágenes tienen 300x300 pixeles, ademas como son imágenes en RGB cada una de ellas tiene una profundidad de 3 capas, de modo que cada una de ellas mostrará en el rango 0, 255 la intensidad del color en el pixel analizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc67e5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2520, 120, 120, 3), (372, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reescalemos primero las imagenes a fin de ocupar menos memoria:\n",
    "train, test = list(), list()\n",
    "size = 120\n",
    "for image in X_train:\n",
    "    train.append(tf.image.resize(image, [size,size]))\n",
    "for image in X_test:\n",
    "    test.append(tf.image.resize(image, [size,size]))\n",
    "\n",
    "X_test = np.array(train)\n",
    "X_train = np.array(train)\n",
    "y_train = keras.utils.to_categorical(y_train, 3)\n",
    "y_test = keras.utils.to_categorical(y_test, 3)\n",
    "    \n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c628e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# escalemos los datos al rango 0, 1:\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "321f023f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 118, 118, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 39, 39, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 37, 37, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 18, 18, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 20736)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1327168   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,346,755\n",
      "Trainable params: 1,346,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creemos el modelo:\n",
    "model = Sequential()\n",
    "model.add(Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=(3,3),\n",
    "    activation='relu',\n",
    "    input_shape=X_train[0].shape))\n",
    "model.add(MaxPooling2D((3,3)))\n",
    "model.add(Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=(3,3),\n",
    "    activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09990727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train, \n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd75d815",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88710b",
   "metadata": {},
   "source": [
    "## Notas:\n",
    "\n",
    "> Keras.Conv2D:\n",
    ">   * filters: int(), Dimension de la salida de la convolución\n",
    ">   * kernel_size: int / tuple(int, int) / list(int, int), matriz de convolución (n_px * n_px)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ab0cc2",
   "metadata": {},
   "source": [
    "## Bibliografia:\n",
    "\n",
    "   * Stack Overflow: https://stackoverflow.com\n",
    "   * Elemento bibliografico 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750da7ba",
   "metadata": {},
   "source": [
    "### Autor\n",
    "\n",
    "   - **Name:** Elidas\n",
    "   - **Email:** pyro.elidas@gmail.com\n",
    "   - **Python version:** 3.9.1\n",
    "   - **Date:** ${DATE}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
