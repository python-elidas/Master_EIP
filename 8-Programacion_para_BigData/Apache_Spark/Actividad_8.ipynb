{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a20b59",
   "metadata": {},
   "source": [
    "# Actividad 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4779ae4",
   "metadata": {},
   "source": [
    "### Analisis y entendimiento del Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b26e69c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empecemos importando las librerias necesarisas\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator as MCE\n",
    "from pyspark.ml.classification import DecisionTreeClassifier as DTC\n",
    "from pyspark.ml.classification import GBTClassifier as GBTC\n",
    "from pyspark.ml.classification import RandomForestClassifier as RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d51475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/09/23 23:57:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Ceemos la sesion:\n",
    "spark = SparkSession.builder.appName('IrisDS').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00abf33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
      "|  6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|\n",
      "|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|\n",
      "|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|\n",
      "|  9|          4.4|         2.9|          1.4|         0.2|Iris-setosa|\n",
      "| 10|          4.9|         3.1|          1.5|         0.1|Iris-setosa|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#leamos el data set\n",
    "df = spark.read.csv('Iris_DataSheet.csv', header=True).cache()\n",
    "# primer vistazo\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e54143d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lineas del data set:\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e03ae4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Id', 'string'),\n",
       " ('SepalLengthCm', 'string'),\n",
       " ('SepalWidthCm', 'string'),\n",
       " ('PetalLengthCm', 'string'),\n",
       " ('PetalWidthCm', 'string'),\n",
       " ('Species', 'string')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columnas y su tipo:\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ace31f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adecuemos el data set dando el fromato adecuado a las columnas numéricas\n",
    "df = df.select(\n",
    "    col('Id').cast('int'),\n",
    "    col('SepalLengthCm').cast('float'),\n",
    "    col('SepalWidthCm').cast('float'),\n",
    "    col('PetalLengthCm').cast('float'),\n",
    "    col('PetalWidthCm').cast('float'),\n",
    "    col('Species')\n",
    ")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d232ff0b",
   "metadata": {},
   "source": [
    "## Transformar en vector los datos numéricos empleando Vector Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42371946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo primero, definamos que datos(columnas) se han de combertir en vector:\n",
    "req_feat = ['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']\n",
    "\n",
    "# creemos los vectores\n",
    "assembler = VectorAssembler(inputCols=req_feat, outputCol='Sizes')\n",
    "\n",
    "# añadamoslo al dataset\n",
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5d84a44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+--------------------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|               Sizes|\n",
      "+---+-------------+------------+-------------+------------+-----------+--------------------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|[5.09999990463256...|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|[4.90000009536743...|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|[4.69999980926513...|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|[4.59999990463256...|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|[5.0,3.5999999046...|\n",
      "|  6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|[5.40000009536743...|\n",
      "|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|[4.59999990463256...|\n",
      "|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|[5.0,3.4000000953...|\n",
      "|  9|          4.4|         2.9|          1.4|         0.2|Iris-setosa|[4.40000009536743...|\n",
      "| 10|          4.9|         3.1|          1.5|         0.1|Iris-setosa|[4.90000009536743...|\n",
      "+---+-------------+------------+-------------+------------+-----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9714c37c",
   "metadata": {},
   "source": [
    "## Transformar los datos correspondientes a la columna especies usando StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd579cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convirtamos la columna 'Species' en una columnas numérica\n",
    "df = StringIndexer(inputCol='Species', outputCol='SpeciesID').fit(df).transform(df)\n",
    "# A setosa le asignará el 1, a versicolor el 2 y a virginica, el 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67ba538e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+--------------------+---------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|               Sizes|SpeciesID|\n",
      "+---+-------------+------------+-------------+------------+-----------+--------------------+---------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|[5.09999990463256...|      0.0|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|[4.90000009536743...|      0.0|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|[4.69999980926513...|      0.0|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|[4.59999990463256...|      0.0|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|[5.0,3.5999999046...|      0.0|\n",
      "|  6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|[5.40000009536743...|      0.0|\n",
      "|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|[4.59999990463256...|      0.0|\n",
      "|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|[5.0,3.4000000953...|      0.0|\n",
      "|  9|          4.4|         2.9|          1.4|         0.2|Iris-setosa|[4.40000009536743...|      0.0|\n",
      "| 10|          4.9|         3.1|          1.5|         0.1|Iris-setosa|[4.90000009536743...|      0.0|\n",
      "+---+-------------+------------+-------------+------------+-----------+--------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8400a309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Id: int, SepalLengthCm: float, SepalWidthCm: float, PetalLengthCm: float, PetalWidthCm: float, Sizes: vector, SpeciesID: double]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quitemos la columna Species\n",
    "df.drop('Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d04de3",
   "metadata": {},
   "source": [
    "**Creemos ahora las particiones Train Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "106b4708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empelaremos el 85% del data set para Train y el 15% para test\n",
    "(train, test) = df.randomSplit([0.85, 0.15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1d8aa1",
   "metadata": {},
   "source": [
    "## Calcular la predicción y la precisión del modelo empleando Decision Tree Classifier (DTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "022ead7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de nada, creemos el modelo de prediccion\n",
    "dtc = DTC(labelCol='SpeciesID', featuresCol='Sizes',maxDepth=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d3cc85",
   "metadata": {},
   "source": [
    "Aumentando el valor de 'maxDepth' de 5 a 10 la prediccion del modelo mejora, al menos en este caso, de ahi para arriba parece que se crea algo de overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "746d04e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenemos el modelo:\n",
    "dtc_model = dtc.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ad8bd2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "      <th>Sizes</th>\n",
       "      <th>SpeciesID</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[4.699999809265137, 3.200000047683716, 1.29999...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[43.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[4.400000095367432, 2.9000000953674316, 1.3999...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[43.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[5.400000095367432, 3.700000047683716, 1.5, 0....</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[43.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[5.099999904632568, 3.299999952316284, 1.70000...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[43.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[4.900000095367432, 3.0999999046325684, 1.5, 0...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[43.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species  \\\n",
       "0   3            4.7           3.2            1.3           0.2  Iris-setosa   \n",
       "1   9            4.4           2.9            1.4           0.2  Iris-setosa   \n",
       "2  11            5.4           3.7            1.5           0.2  Iris-setosa   \n",
       "3  24            5.1           3.3            1.7           0.5  Iris-setosa   \n",
       "4  35            4.9           3.1            1.5           0.1  Iris-setosa   \n",
       "\n",
       "                                               Sizes  SpeciesID  \\\n",
       "0  [4.699999809265137, 3.200000047683716, 1.29999...        0.0   \n",
       "1  [4.400000095367432, 2.9000000953674316, 1.3999...        0.0   \n",
       "2  [5.400000095367432, 3.700000047683716, 1.5, 0....        0.0   \n",
       "3  [5.099999904632568, 3.299999952316284, 1.70000...        0.0   \n",
       "4  [4.900000095367432, 3.0999999046325684, 1.5, 0...        0.0   \n",
       "\n",
       "      rawPrediction      probability  prediction  \n",
       "0  [43.0, 0.0, 0.0]  [1.0, 0.0, 0.0]         0.0  \n",
       "1  [43.0, 0.0, 0.0]  [1.0, 0.0, 0.0]         0.0  \n",
       "2  [43.0, 0.0, 0.0]  [1.0, 0.0, 0.0]         0.0  \n",
       "3  [43.0, 0.0, 0.0]  [1.0, 0.0, 0.0]         0.0  \n",
       "4  [43.0, 0.0, 0.0]  [1.0, 0.0, 0.0]         0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generemos una prediccion:\n",
    "dtc_pred = dtc_model.transform(test)\n",
    "dtc_pred.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51c33c0",
   "metadata": {},
   "source": [
    "### Evaluemos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1b1f883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuremos el evaluador:\n",
    "evaluator = MCE(labelCol='SpeciesID', predictionCol='prediction', metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b250d9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC test accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "#  Ahora si, evaluemos el modelo:\n",
    "accuracy = evaluator.evaluate(dtc_pred)\n",
    "print(f'DTC test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73dea4",
   "metadata": {},
   "source": [
    "## Calcular la predicción y la precisión del modelo empleando Gradient-boosted tree classifier GBTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae61ec35",
   "metadata": {},
   "source": [
    "**Como el modelo GBTC solo permite trabajar con predicciones binarias, será necesario adecuar los datos:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a05cfd46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "      <th>Sizes</th>\n",
       "      <th>SpeciesID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[5.099999904632568, 3.5, 1.399999976158142, 0....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[4.900000095367432, 3.0, 1.399999976158142, 0....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[4.699999809265137, 3.200000047683716, 1.29999...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[4.599999904632568, 3.0999999046325684, 1.5, 0...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[5.0, 3.5999999046325684, 1.399999976158142, 0...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species  \\\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa   \n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa   \n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa   \n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa   \n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa   \n",
       "\n",
       "                                               Sizes  SpeciesID  \n",
       "0  [5.099999904632568, 3.5, 1.399999976158142, 0....        0.0  \n",
       "1  [4.900000095367432, 3.0, 1.399999976158142, 0....        0.0  \n",
       "2  [4.699999809265137, 3.200000047683716, 1.29999...        0.0  \n",
       "3  [4.599999904632568, 3.0999999046325684, 1.5, 0...        0.0  \n",
       "4  [5.0, 3.5999999046325684, 1.399999976158142, 0...        0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convirtamos el data frame que tenemos a pandas:\n",
    "pdf = df.toPandas()\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "566d02f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalicemos los datos de froma que solo tengamos predicciones binarias:\n",
    "pdf = pd.get_dummies(pdf, columns=['SpeciesID'], drop_first = True)\n",
    "\n",
    "# cambiemos el tipo de ddato para que se pueda trabajer con el mas adelante:\n",
    "pdf = pdf.astype({'SpeciesID_1.0': 'float', 'SpeciesID_2.0': 'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b1d7df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 int32\n",
       "SepalLengthCm    float32\n",
       "SepalWidthCm     float32\n",
       "PetalLengthCm    float32\n",
       "PetalWidthCm     float32\n",
       "Species           object\n",
       "Sizes             object\n",
       "SpeciesID_1.0    float64\n",
       "SpeciesID_2.0    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostremos el resultado:\n",
    "pdf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcee101",
   "metadata": {},
   "source": [
    "Una vez hemos llegado a este punto, crearemos dos particiones del modelo, para ello:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dff3216a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Id', 'bigint'),\n",
       " ('SepalLengthCm', 'double'),\n",
       " ('SepalWidthCm', 'double'),\n",
       " ('PetalLengthCm', 'double'),\n",
       " ('PetalWidthCm', 'double'),\n",
       " ('Species', 'string'),\n",
       " ('Sizes', 'vector'),\n",
       " ('SpeciesID_1.0', 'double'),\n",
       " ('SpeciesID_2.0', 'double')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reconvertimos el data frmae a spark data frame:\n",
    "sdf = spark.createDataFrame(pdf)\n",
    "sdf_col=sdf.columns\n",
    "sdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdc40739",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve '`SpeciesID_1.0`' given input columns: [Id, PetalLengthCm, PetalWidthCm, SepalLengthCm, SepalWidthCm, Sizes, Species, SpeciesID];\n'Project [Sizes#501, unresolvedalias(cast('SpeciesID_1.0 as int), None), unresolvedalias(cast('SpeciesID_2.0 as int), None)]\n+- Project [Id#340, SepalLengthCm#341, SepalWidthCm#342, PetalLengthCm#343, PetalWidthCm#344, Species#21, Sizes#501, UDF(cast(Species#21 as string)) AS SpeciesID#806]\n   +- Project [Id#340, SepalLengthCm#341, SepalWidthCm#342, PetalLengthCm#343, PetalWidthCm#344, Species#21, UDF(struct(SepalLengthCm_double_VectorAssembler_ea7370da9b12, cast(SepalLengthCm#341 as double), SepalWidthCm_double_VectorAssembler_ea7370da9b12, cast(SepalWidthCm#342 as double), PetalLengthCm_double_VectorAssembler_ea7370da9b12, cast(PetalLengthCm#343 as double), PetalWidthCm_double_VectorAssembler_ea7370da9b12, cast(PetalWidthCm#344 as double))) AS Sizes#501]\n      +- Project [cast(Id#16 as int) AS Id#340, cast(SepalLengthCm#17 as float) AS SepalLengthCm#341, cast(SepalWidthCm#18 as float) AS SepalWidthCm#342, cast(PetalLengthCm#19 as float) AS PetalLengthCm#343, cast(PetalWidthCm#20 as float) AS PetalWidthCm#344, Species#21]\n         +- Relation[Id#16,SepalLengthCm#17,SepalWidthCm#18,PetalLengthCm#19,PetalWidthCm#20,Species#21] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1524/1052289787.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Tendremos que adecuar los datos nuevamente:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m sdf = df.select(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdf_col\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdf_col\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdf_col\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1667\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m         \"\"\"\n\u001b[0;32m-> 1669\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '`SpeciesID_1.0`' given input columns: [Id, PetalLengthCm, PetalWidthCm, SepalLengthCm, SepalWidthCm, Sizes, Species, SpeciesID];\n'Project [Sizes#501, unresolvedalias(cast('SpeciesID_1.0 as int), None), unresolvedalias(cast('SpeciesID_2.0 as int), None)]\n+- Project [Id#340, SepalLengthCm#341, SepalWidthCm#342, PetalLengthCm#343, PetalWidthCm#344, Species#21, Sizes#501, UDF(cast(Species#21 as string)) AS SpeciesID#806]\n   +- Project [Id#340, SepalLengthCm#341, SepalWidthCm#342, PetalLengthCm#343, PetalWidthCm#344, Species#21, UDF(struct(SepalLengthCm_double_VectorAssembler_ea7370da9b12, cast(SepalLengthCm#341 as double), SepalWidthCm_double_VectorAssembler_ea7370da9b12, cast(SepalWidthCm#342 as double), PetalLengthCm_double_VectorAssembler_ea7370da9b12, cast(PetalLengthCm#343 as double), PetalWidthCm_double_VectorAssembler_ea7370da9b12, cast(PetalWidthCm#344 as double))) AS Sizes#501]\n      +- Project [cast(Id#16 as int) AS Id#340, cast(SepalLengthCm#17 as float) AS SepalLengthCm#341, cast(SepalWidthCm#18 as float) AS SepalWidthCm#342, cast(PetalLengthCm#19 as float) AS PetalLengthCm#343, cast(PetalWidthCm#20 as float) AS PetalWidthCm#344, Species#21]\n         +- Relation[Id#16,SepalLengthCm#17,SepalWidthCm#18,PetalLengthCm#19,PetalWidthCm#20,Species#21] csv\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12b7bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creemos un nuevo vector con sizes y speciesID_1.0 y con ello un nuevo data set\n",
    "req = \n",
    "assembler = VectorAssembler(inputCols=req, outputCol='Sizes+')\n",
    "\n",
    "# añadamoslo al dataset y eliminemos las colunas que sobran\n",
    "sdf_2 = assembler.transform(sdf).drop('Sizes', sdf_col[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6111e1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# primero crearemos la particion prescindiendo de la columna 'SpeciesID_2.0' para realizar ña primera predicción\n",
    "(train_1, test_1) = sdf.drop(sdf_col[-1]).randomSplit([0.85, 0.15])\n",
    "\n",
    "# Segundo, crearemos la particion para la segunda prediccion:\n",
    "(train_2, test_2) = sdf_2.randomSplit([0.85, 0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc4d5b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creemos el modelo de la primera prediccion:\n",
    "gbtc_1 = GBTC(labelCol=sdf_col[-2], featuresCol='Sizes', maxIter=10)  # labelCol == SpeciesID_1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0edd1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenemos el modelo de la primera predicción:\n",
    "gbtc_model_1 = gbtc_1.fit(train_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac620c2f",
   "metadata": {},
   "source": [
    "**no entiendo porque pero no me deja hacer la prediccion, continuare como si me dejara** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a877ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# una vez creado el modelo, hagamos la prediccion para la especie Versicolor:\n",
    "gbtc_pred_1 = gbtc_model_1.transform(test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62e900c",
   "metadata": {},
   "source": [
    "Una vez tenemos la prediccion para Versicolor, haremos para Virginica, pero la haremos de un modo especial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f74d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptamos la prediccion obtenida a nuestras necesidades:\n",
    "req = sdf_col[-3:-2]\n",
    "assembler = VectorAssembler(inputCols=req, outputCol='Sizes+')\n",
    "\n",
    "# añadamoslo al dataset y eliminemos las colunas que sobran\n",
    "sdf_2 = assembler.transform(sdf).drop('Sizes', sdf_col[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe30e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crearemos un nuevo modelo predictivo empleando columnas del segundo data set:\n",
    "gbtc_2 = GBTC(labelCol=sdf_col[-1], featuresCol='Sizes+', maxIter=10) # labelCol == SpeciesID_2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3d37b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenaremos el modelo empleando test_2 obtenido de sdf_2:\n",
    "gbtc_model_2 = gbtc_2.fit(train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138b025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora en vez de realizar la prediccion sobre "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a62b58d",
   "metadata": {},
   "source": [
    "### Bibliografia:\n",
    "   * Páfginas Web:\n",
    "      * https://sparkbyexamples.com/pyspark/convert-pandas-to-pyspark-dataframe/\n",
    "   * Otros:\n",
    "       * Ejercicio 5 de la asignatura Fundamento de Big Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
